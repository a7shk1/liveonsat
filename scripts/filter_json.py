# scripts/filter_json.py
# -*- coding: utf-8 -*-
import json
import re
import unicodedata
from pathlib import Path
import requests
import os

# ===== ØªØ±Ø¬Ù…Ø© Ø§Ø®ØªÙŠØ§Ø±ÙŠØ© (fallback) =====
try:
    from deep_translator import GoogleTranslator
except Exception:
    GoogleTranslator = None

# ===== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª =====
REPO_ROOT = Path(__file__).resolve().parents[1]
MATCHES_DIR = REPO_ROOT / "matches"
INPUT_PATH = MATCHES_DIR / "liveonsat_raw.json"        # Ù†ÙƒÙ…Ù‘Ù„ Ù…Ù†Ù‡ Ø§Ù„Ù‚Ù†ÙˆØ§Øª
OUTPUT_PATH = MATCHES_DIR / "filtered_matches.json"
YALLASHOOT_URL = "https://raw.githubusercontent.com/a7shk1/yallashoot/refs/heads/main/matches/today.json"

# ===== Ø£Ø¯ÙˆØ§Øª Ø¹Ø§Ù…Ø© =====
AR_LETTERS_RE = re.compile(r'[\u0600-\u06FF]')
EMOJI_MISC_RE = re.compile(r'[\u2600-\u27BF\U0001F300-\U0001FAFF]+')
BEIN_RE = re.compile(r'bein\s*sports?', re.I)

def strip_accents(s: str) -> str:
    return ''.join(c for c in unicodedata.normalize("NFKD", s) if not unicodedata.combining(c))

def normalize_text(text: str) -> str:
    if not text:
        return ""
    text = str(text)
    text = EMOJI_MISC_RE.sub("", text)
    text = re.sub(r"\(.*?\)", "", text)
    text = strip_accents(text)
    text = text.lower()
    text = text.replace("&", "and")
    text = re.sub(r"\b(fc|sc|cf|u\d+)\b", "", text)  # Ø´ÙŠÙ„ Ù„Ø§Ø­Ù‚Ø§Øª Ø´Ø§Ø¦Ø¹Ø©
    text = text.replace("Ø§Ù„", "")
    # Ø¨Ø¯Ø§Ø¦Ù„ Ø¹Ø±Ø¨ÙŠØ© Ø´Ø§Ø¦Ø¹Ø©
    text = text.replace("Ù‰", "ÙŠ").replace("Ø©", "Ù‡").replace("Ø£", "Ø§").replace("Ø¥", "Ø§").replace("Ø¢", "Ø§")
    text = text.replace("Ù€", "")  # ØªØ·ÙˆÙŠÙ„
    text = text.replace(" ", "").replace("-", "").replace("_", "")
    text = re.sub(r"[^a-z0-9\u0600-\u06FF]", "", text)
    return text.strip()

def unique_preserving(seq):
    seen, out = set(), []
    for x in seq:
        k = str(x).lower().strip()
        if k not in seen:
            seen.add(k)
            out.append(x)
    return out

def to_list_channels(val):
    if isinstance(val, list):
        return [str(x).strip() for x in val if str(x).strip()]
    if isinstance(val, str):
        s = val.strip()
        if not s: return []
        parts = re.split(r"\s*(?:,|ØŒ|/|\||&| Ùˆ | and )\s*", s, flags=re.I)
        return [p for p in parts if p]
    return []

def clean_channel_display(name: str) -> str:
    if not name: return ""
    s = str(name)
    s = EMOJI_MISC_RE.sub("", s)
    s = re.sub(r"\s*\((?:\$?\/?geo\/?R|geo\/?R|\$\/?geo)\)\s*", "", s, flags=re.I)
    s = re.sub(r"ğŸ“º|\[online\]|\[app\]", "", s, flags=re.I)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def is_bein_channel(name: str) -> bool:
    return bool(BEIN_RE.search(name or ""))

# ===== Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø© (ÙÙ„ØªØ±Ø© ØµØ§Ø±Ù…Ø©) =====
SUPPORTED_CHANNELS = [
    "MATCH! Futbol 1", "MATCH! Futbol 2", "MATCH! Futbol 3",
    "Football HD",
    "Sport TV1 Portugal HD", "Sport TV2 Portugal HD",
    "ESPN 1 Brazil", "ESPN 2 Brazil", "ESPN 3 Brazil", "ESPN 4 Brazil", "ESPN 5 Brazil", "ESPN 6 Brazil", "ESPN 7 Brazil",
    "DAZN 1 Portugal HD", "DAZN 2 Portugal HD", "DAZN 3 Portugal HD", "DAZN 4 Portugal HD", "DAZN 5 Portugal HD", "DAZN 6 Portugal HD",
    "MATCH! Premier HD", "Sky Sports Main Event HD", "Sky Sport Premier League HD", "IRIB Varzesh HD",
    "Persiana Sport HD", "MBC Action HD", "TNT Sports 1 HD", "TNT Sports 2 HD", "TNT Sports HD",
    "MBC masrHD", "MBC masr2HD", "ssc1 hd", "ssc2 hd", "Shahid MBC",
]
_supported_tokens = set()
for c in SUPPORTED_CHANNELS:
    cl = c.lower()
    _supported_tokens.add(cl)
    _supported_tokens.add(cl.replace(" hd", ""))
SUPPORTED_TOKENS = list(_supported_tokens)

def is_supported_channel(name: str) -> bool:
    if not name: return False
    n = name.lower()
    return any(tok in n for tok in SUPPORTED_TOKENS)

# =====================================================================
# Ù‚Ø§Ù…ÙˆØ³ Ø¶Ø®Ù… ÙŠØ¯ÙˆÙŠ (Ø£Ù†Ø¯ÙŠØ© Ø¹Ø±Ø¨ÙŠØ© + Ø£ÙˆØ±ÙˆØ¨ÙŠØ© + Ù…Ù†ØªØ®Ø¨Ø§Øª) â€” Ù…ÙˆØ³Ù‘Ø¹ Ù„Ù„ØºØ§ÙŠØ©
# Ù…Ù„Ø§Ø­Ø¸Ø©: ØªÙ‚Ø¯Ø± ØªØ¶ÙŠÙ Ù„Ù‡ Ù„Ø§Ø­Ù‚Ù‹Ø§ Ø¨Ø­Ø±ÙŠØ©ØŒ Ø§Ù„Ø³ÙƒØ±Ø¨Øª ÙŠØ³ØªØ®Ø¯Ù…Ù‡ Ø£ÙˆÙ„Ù‹Ø§ Ù‚Ø¨Ù„ Ø£ÙŠ ØªØ±Ø¬Ù…Ø©
# =====================================================================

EN2AR = {
    # ----- Ù…Ù†ØªØ®Ø¨Ø§Øª Ø¹Ø±Ø¨ÙŠØ© -----
    "Iraq": "Ø§Ù„Ø¹Ø±Ø§Ù‚", "Saudi Arabia": "Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©", "Qatar": "Ù‚Ø·Ø±", "United Arab Emirates": "Ø§Ù„Ø¥Ù…Ø§Ø±Ø§Øª",
    "UAE": "Ø§Ù„Ø¥Ù…Ø§Ø±Ø§Øª", "Kuwait": "Ø§Ù„ÙƒÙˆÙŠØª", "Bahrain": "Ø§Ù„Ø¨Ø­Ø±ÙŠÙ†", "Oman": "Ø¹ÙÙ…Ø§Ù†", "Jordan": "Ø§Ù„Ø£Ø±Ø¯Ù†",
    "Syria": "Ø³ÙˆØ±ÙŠØ§", "Lebanon": "Ù„Ø¨Ù†Ø§Ù†", "Palestine": "ÙÙ„Ø³Ø·ÙŠÙ†", "Yemen": "Ø§Ù„ÙŠÙ…Ù†", "Egypt": "Ù…ØµØ±",
    "Libya": "Ù„ÙŠØ¨ÙŠØ§", "Tunisia": "ØªÙˆÙ†Ø³", "Algeria": "Ø§Ù„Ø¬Ø²Ø§Ø¦Ø±", "Morocco": "Ø§Ù„Ù…ØºØ±Ø¨",
    "Somalia": "Ø§Ù„ØµÙˆÙ…Ø§Ù„", "Sudan": "Ø§Ù„Ø³ÙˆØ¯Ø§Ù†", "Mauritania": "Ù…ÙˆØ±ÙŠØªØ§Ù†ÙŠØ§",

    # ----- Ù…Ù†ØªØ®Ø¨Ø§Øª Ø¹Ø§Ù„Ù…ÙŠØ© Ù…Ø´Ù‡ÙˆØ±Ø© -----
    "Brazil": "Ø§Ù„Ø¨Ø±Ø§Ø²ÙŠÙ„", "Argentina": "Ø§Ù„Ø£Ø±Ø¬Ù†ØªÙŠÙ†", "Germany": "Ø£Ù„Ù…Ø§Ù†ÙŠØ§", "France": "ÙØ±Ù†Ø³Ø§",
    "Spain": "Ø¥Ø³Ø¨Ø§Ù†ÙŠØ§", "Italy": "Ø¥ÙŠØ·Ø§Ù„ÙŠØ§", "England": "Ø¥Ù†Ø¬Ù„ØªØ±Ø§", "Portugal": "Ø§Ù„Ø¨Ø±ØªØºØ§Ù„",
    "Netherlands": "Ù‡ÙˆÙ„Ù†Ø¯Ø§", "Belgium": "Ø¨Ù„Ø¬ÙŠÙƒØ§", "Croatia": "ÙƒØ±ÙˆØ§ØªÙŠØ§", "Uruguay": "Ø£ÙˆØ±ÙˆØ¬ÙˆØ§ÙŠ",
    "USA": "Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø©", "United States": "Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø©", "Mexico": "Ø§Ù„Ù…ÙƒØ³ÙŠÙƒ",
    "Japan": "Ø§Ù„ÙŠØ§Ø¨Ø§Ù†", "South Korea": "ÙƒÙˆØ±ÙŠØ§ Ø§Ù„Ø¬Ù†ÙˆØ¨ÙŠØ©", "Australia": "Ø£Ø³ØªØ±Ø§Ù„ÙŠØ§",

    # ----- Ø£Ù†Ø¯ÙŠØ© Ø³Ø¹ÙˆØ¯ÙŠØ© -----
    "Al Hilal": "Ø§Ù„Ù‡Ù„Ø§Ù„", "Al-Hilal": "Ø§Ù„Ù‡Ù„Ø§Ù„",
    "Al Nassr": "Ø§Ù„Ù†ØµØ±", "Al-Nassr": "Ø§Ù„Ù†ØµØ±",
    "Al Ittihad": "Ø§Ù„Ø§ØªØ­Ø§Ø¯", "Al-Ittihad": "Ø§Ù„Ø§ØªØ­Ø§Ø¯",
    "Al Ahli": "Ø§Ù„Ø£Ù‡Ù„ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ", "Al-Ahli": "Ø§Ù„Ø£Ù‡Ù„ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ",
    "Al Shabab": "Ø§Ù„Ø´Ø¨Ø§Ø¨", "Al-Shabab": "Ø§Ù„Ø´Ø¨Ø§Ø¨",
    "Al Ettifaq": "Ø§Ù„Ø§ØªÙØ§Ù‚", "Al-Ettifaq": "Ø§Ù„Ø§ØªÙØ§Ù‚",
    "Al Fayha": "Ø§Ù„ÙÙŠØ­Ø§Ø¡", "Al-Fayha": "Ø§Ù„ÙÙŠØ­Ø§Ø¡",
    "Al Raed": "Ø§Ù„Ø±Ø§Ø¦Ø¯", "Al-Raed": "Ø§Ù„Ø±Ø§Ø¦Ø¯",
    "Al Taawoun": "Ø§Ù„ØªØ¹Ø§ÙˆÙ†", "Al-Taawoun": "Ø§Ù„ØªØ¹Ø§ÙˆÙ†",
    "Abha": "Ø£Ø¨Ù‡Ø§", "Damac": "Ø¶Ù…Ùƒ", "Al Fateh": "Ø§Ù„ÙØªØ­", "Al-Fateh": "Ø§Ù„ÙØªØ­",
    "Al Okhdood": "Ø§Ù„Ø£Ø®Ø¯ÙˆØ¯", "Al-Okhdood": "Ø§Ù„Ø£Ø®Ø¯ÙˆØ¯",
    "Al Riyadh": "Ø§Ù„Ø±ÙŠØ§Ø¶", "Al-Riyadh": "Ø§Ù„Ø±ÙŠØ§Ø¶",
    "Al Wehda": "Ø§Ù„ÙˆØ­Ø¯Ø©", "Al-Wehda": "Ø§Ù„ÙˆØ­Ø¯Ø©",
    "Al Qadsiah": "Ø§Ù„Ù‚Ø§Ø¯Ø³ÙŠØ©", "Al-Qadsiah": "Ø§Ù„Ù‚Ø§Ø¯Ø³ÙŠØ©",

    # ----- Ø£Ù†Ø¯ÙŠØ© Ù‚Ø·Ø± -----
    "Al Sadd": "Ø§Ù„Ø³Ø¯", "Al-Sadd": "Ø§Ù„Ø³Ø¯",
    "Al Duhail": "Ø§Ù„Ø¯Ø­ÙŠÙ„", "Al-Duhail": "Ø§Ù„Ø¯Ø­ÙŠÙ„",
    "Al Gharafa": "Ø§Ù„ØºØ±Ø§ÙØ©", "Al-Gharafa": "Ø§Ù„ØºØ±Ø§ÙØ©",
    "Al Rayyan": "Ø§Ù„Ø±ÙŠØ§Ù†", "Al-Rayyan": "Ø§Ù„Ø±ÙŠØ§Ù†",
    "Qatar SC": "Ù‚Ø·Ø±", "Al Arabi": "Ø§Ù„Ø¹Ø±Ø¨ÙŠ", "Al-Arabi": "Ø§Ù„Ø¹Ø±Ø¨ÙŠ",
    "Al Wakrah": "Ø§Ù„ÙˆÙƒØ±Ø©", "Al-Wakrah": "Ø§Ù„ÙˆÙƒØ±Ø©",

    # ----- Ø£Ù†Ø¯ÙŠØ© Ø§Ù„Ø¥Ù…Ø§Ø±Ø§Øª -----
    "Al Ain": "Ø§Ù„Ø¹ÙŠÙ†", "Al-Ain": "Ø§Ù„Ø¹ÙŠÙ†",
    "Al Wahda": "Ø§Ù„ÙˆØ­Ø¯Ø©", "Al-Wahda": "Ø§Ù„ÙˆØ­Ø¯Ø©",
    "Al Jazira": "Ø§Ù„Ø¬Ø²ÙŠØ±Ø©", "Al-Jazira": "Ø§Ù„Ø¬Ø²ÙŠØ±Ø©",
    "Shabab Al Ahli": "Ø´Ø¨Ø§Ø¨ Ø§Ù„Ø£Ù‡Ù„ÙŠ", "Al Nasr Dubai": "Ø§Ù„Ù†ØµØ± Ø§Ù„Ø¥Ù…Ø§Ø±Ø§ØªÙŠ",
    "Sharjah": "Ø§Ù„Ø´Ø§Ø±Ù‚Ø©", "Khor Fakkan": "Ø®ÙˆØ±ÙÙƒØ§Ù†", "Bani Yas": "Ø¨Ù†ÙŠ ÙŠØ§Ø³",

    # ----- Ø£Ù†Ø¯ÙŠØ© Ø§Ù„Ø¹Ø±Ø§Ù‚ -----
    "Al Shorta": "Ø§Ù„Ø´Ø±Ø·Ø©", "Al-Shorta": "Ø§Ù„Ø´Ø±Ø·Ø©",
    "Al Zawraa": "Ø§Ù„Ø²ÙˆØ±Ø§Ø¡", "Al-Zawraa": "Ø§Ù„Ø²ÙˆØ±Ø§Ø¡",
    "Al Quwa Al Jawiya": "Ø§Ù„Ù‚ÙˆØ© Ø§Ù„Ø¬ÙˆÙŠØ©", "Al-Quwa Al-Jawiya": "Ø§Ù„Ù‚ÙˆØ© Ø§Ù„Ø¬ÙˆÙŠØ©",
    "Naft Al Wasat": "Ù†ÙØ· Ø§Ù„ÙˆØ³Ø·", "Al Najaf": "Ø§Ù„Ù†Ø¬Ù",
    "Karbalaa": "ÙƒØ±Ø¨Ù„Ø§Ø¡", "Duhok": "Ø¯Ù‡ÙˆÙƒ", "Erbil": "Ø£Ø±Ø¨ÙŠÙ„", "Al Mina'a": "Ø§Ù„Ù…ÙŠÙ†Ø§Ø¡", "Al-Minaa": "Ø§Ù„Ù…ÙŠÙ†Ø§Ø¡",

    # ----- Ø£Ù†Ø¯ÙŠØ© Ø§Ù„Ù…ØºØ±Ø¨ -----
    "Wydad": "Ø§Ù„ÙˆØ¯Ø§Ø¯", "Raja": "Ø§Ù„Ø±Ø¬Ø§Ø¡", "FUS Rabat": "Ø§Ù„ÙØªØ­ Ø§Ù„Ø±Ø¨Ø§Ø·ÙŠ",
    "RS Berkane": "Ù†Ù‡Ø¶Ø© Ø¨Ø±ÙƒØ§Ù†", "Hassania Agadir": "Ø­Ø³Ù†ÙŠØ© Ø£ÙƒØ§Ø¯ÙŠØ±",
    "Ittihad Tanger": "Ø§ØªØ­Ø§Ø¯ Ø·Ù†Ø¬Ø©", "OC Safi": "Ø£ÙˆÙ„Ù…Ø¨ÙŠÙƒ Ø¢Ø³ÙÙŠ", "Olympic Safi": "Ø£ÙˆÙ„Ù…Ø¨ÙŠÙƒ Ø¢Ø³ÙÙŠ",

    # ----- Ø£Ù†Ø¯ÙŠØ© ØªÙˆÙ†Ø³ -----
    "Esperance": "Ø§Ù„ØªØ±Ø¬ÙŠ", "Etoile du Sahel": "Ø§Ù„Ù†Ø¬Ù… Ø§Ù„Ø³Ø§Ø­Ù„ÙŠ",
    "Club Africain": "Ø§Ù„Ù†Ø§Ø¯ÙŠ Ø§Ù„Ø¥ÙØ±ÙŠÙ‚ÙŠ", "CS Sfaxien": "Ø§Ù„ØµÙØ§Ù‚Ø³ÙŠ",

    # ----- Ø£Ù†Ø¯ÙŠØ© Ø§Ù„Ø¬Ø²Ø§Ø¦Ø± -----
    "USM Alger": "Ø§ØªØ­Ø§Ø¯ Ø§Ù„Ø¹Ø§ØµÙ…Ø©", "JS Kabylie": "Ø´Ø¨ÙŠØ¨Ø© Ø§Ù„Ù‚Ø¨Ø§Ø¦Ù„",
    "MC Alger": "Ù…ÙˆÙ„ÙˆØ¯ÙŠØ© Ø§Ù„Ø¬Ø²Ø§Ø¦Ø±",

    # ----- Ø£Ù†Ø¯ÙŠØ© Ù…ØµØ± -----
    "Al Ahly": "Ø§Ù„Ø£Ù‡Ù„ÙŠ", "Zamalek": "Ø§Ù„Ø²Ù…Ø§Ù„Ùƒ", "Pyramids": "Ø¨ÙŠØ±Ø§Ù…ÙŠØ¯Ø²",
    "Ismaily": "Ø§Ù„Ø¥Ø³Ù…Ø§Ø¹ÙŠÙ„ÙŠ", "Al Masry": "Ø§Ù„Ù…ØµØ±ÙŠ", "Smouha": "Ø³Ù…ÙˆØ­Ø©",

    # ----- Ø£Ù†Ø¯ÙŠØ© Ø§Ù„Ø£Ø±Ø¯Ù†/Ø³ÙˆØ±ÙŠØ§/Ù„Ø¨Ù†Ø§Ù† -----
    "Al Faisaly": "Ø§Ù„ÙÙŠØµÙ„ÙŠ", "Al Wehdat": "Ø§Ù„ÙˆØ­Ø¯Ø§Øª",
    "Al Jazeera Amman": "Ø§Ù„Ø¬Ø²ÙŠØ±Ø© (Ø§Ù„Ø£Ø±Ø¯Ù†)", "Shabab Al Ordon": "Ø´Ø¨Ø§Ø¨ Ø§Ù„Ø£Ø±Ø¯Ù†",
    "Al Jaish": "Ø§Ù„Ø¬ÙŠØ´", "Al Karamah": "Ø§Ù„ÙƒØ±Ø§Ù…Ø©",
    "Al Ahed": "Ø§Ù„Ø¹Ù‡Ø¯", "Al Nejmeh": "Ø§Ù„Ù†Ø¬Ù…Ø©",

    # ----- Ø£Ù†Ø¯ÙŠØ© Ø£ÙˆØ±ÙˆØ¨ÙŠØ© ÙƒØ¨ÙŠØ±Ø© -----
    "Real Madrid": "Ø±ÙŠØ§Ù„ Ù…Ø¯Ø±ÙŠØ¯", "Barcelona": "Ø¨Ø±Ø´Ù„ÙˆÙ†Ø©", "Atletico Madrid": "Ø£ØªÙ„ØªÙŠÙƒÙˆ Ù…Ø¯Ø±ÙŠØ¯",
    "Sevilla": "Ø¥Ø´Ø¨ÙŠÙ„ÙŠØ©", "Valencia": "ÙØ§Ù„Ù†Ø³ÙŠØ§", "Villarreal": "ÙÙŠØ§Ø±ÙŠØ§Ù„", "Real Sociedad": "Ø±ÙŠØ§Ù„ Ø³ÙˆØ³ÙŠØ¯Ø§Ø¯",
    "Espanyol": "Ø¥Ø³Ø¨Ø§Ù†ÙŠÙˆÙ„", "Real Mallorca": "Ø±ÙŠØ§Ù„ Ù…Ø§ÙŠÙˆØ±ÙƒØ§", "Mallorca": "Ø±ÙŠØ§Ù„ Ù…Ø§ÙŠÙˆØ±ÙƒØ§",
    "Bayern Munich": "Ø¨Ø§ÙŠØ±Ù† Ù…ÙŠÙˆÙ†Ø®", "Borussia Dortmund": "Ø¨ÙˆØ±ÙˆØ³ÙŠØ§ Ø¯ÙˆØ±ØªÙ…ÙˆÙ†Ø¯",
    "RB Leipzig": "Ù„Ø§ÙŠØ¨Ø²ÙŠØº", "Bayer Leverkusen": "Ø¨Ø§ÙŠØ± Ù„ÙŠÙØ±ÙƒÙˆØ²Ù†",
    "Inter": "Ø¥Ù†ØªØ± Ù…ÙŠÙ„Ø§Ù†", "Inter Milan": "Ø¥Ù†ØªØ± Ù…ÙŠÙ„Ø§Ù†",
    "AC Milan": "Ù…ÙŠÙ„Ø§Ù†", "Milan": "Ù…ÙŠÙ„Ø§Ù†", "Juventus": "ÙŠÙˆÙÙ†ØªÙˆØ³", "Napoli": "Ù†Ø§Ø¨ÙˆÙ„ÙŠ", "Roma": "Ø±ÙˆÙ…Ø§", "Lazio": "Ù„Ø§ØªØ³ÙŠÙˆ", "Fiorentina": "ÙÙŠÙˆØ±Ù†ØªÙŠÙ†Ø§", "Atalanta": "Ø£ØªØ§Ù„Ø§Ù†ØªØ§", "Torino": "ØªÙˆØ±ÙŠÙ†Ùˆ", "Udinese": "Ø£ÙˆØ¯ÙŠÙ†ÙŠØ²ÙŠ", "Sassuolo": "Ø³Ø§Ø³ÙˆÙ„Ùˆ", "Monza": "Ù…ÙˆÙ†Ø²Ø§", "Como": "ÙƒÙˆÙ…Ùˆ", "Genoa": "Ø¬Ù†ÙˆÙ‰", "Hellas Verona": "Ù‡ÙŠÙ„Ø§Ø³ ÙÙŠØ±ÙˆÙ†Ø§", "Cremonese": "ÙƒØ±ÙŠÙ…ÙˆÙ†ÙŠØ²ÙŠ",
    "Paris Saint-Germain": "Ø¨Ø§Ø±ÙŠØ³ Ø³Ø§Ù† Ø¬ÙŠØ±Ù…Ø§Ù†", "PSG": "Ø¨Ø§Ø±ÙŠØ³ Ø³Ø§Ù† Ø¬ÙŠØ±Ù…Ø§Ù†",
    "Marseille": "Ù…Ø§Ø±Ø³ÙŠÙ„ÙŠØ§", "Lyon": "Ù„ÙŠÙˆÙ†", "Monaco": "Ù…ÙˆÙ†Ø§ÙƒÙˆ", "Lille": "Ù„ÙŠÙ„", "Nice": "Ù†ÙŠØ³", "Rennes": "Ø±ÙŠÙ†", "Brest": "Ø¨Ø±ÙŠØ³Øª", "Strasbourg": "Ø³ØªØ±Ø§Ø³Ø¨ÙˆØ±Øº", "Montpellier": "Ù…ÙˆÙ†Ø¨Ù„ÙŠÙŠÙ‡", "Guingamp": "Ø¬Ø§Ù†Ø¬ÙˆÙ†",
    "Manchester City": "Ù…Ø§Ù†Ø´Ø³ØªØ± Ø³ÙŠØªÙŠ", "Manchester United": "Ù…Ø§Ù†Ø´Ø³ØªØ± ÙŠÙˆÙ†Ø§ÙŠØªØ¯", "Arsenal": "Ø£Ø±Ø³Ù†Ø§Ù„", "Liverpool": "Ù„ÙŠÙØ±Ø¨ÙˆÙ„",
    "Chelsea": "ØªØ´ÙŠÙ„Ø³ÙŠ", "Tottenham Hotspur": "ØªÙˆØªÙ†Ù‡Ø§Ù…", "Tottenham": "ØªÙˆØªÙ†Ù‡Ø§Ù…", "Newcastle United": "Ù†ÙŠÙˆÙƒØ§Ø³Ù„ ÙŠÙˆÙ†Ø§ÙŠØªØ¯", "Aston Villa": "Ø£Ø³ØªÙˆÙ† ÙÙŠÙ„Ø§", "Everton": "Ø¥ÙŠÙØ±ØªÙˆÙ†", "West Ham United": "ÙˆØ³Øª Ù‡Ø§Ù… ÙŠÙˆÙ†Ø§ÙŠØªØ¯", "Wolves": "ÙˆÙ„ÙØ±Ù‡Ø§Ù…Ø¨ØªÙˆÙ†", "Wolverhampton": "ÙˆÙ„ÙØ±Ù‡Ø§Ù…Ø¨ØªÙˆÙ†",
    "Ajax": "Ø£ÙŠØ§ÙƒØ³", "PSV Eindhoven": "Ø¢ÙŠÙ†Ø¯Ù‡ÙˆÙÙ†", "Feyenoord": "ÙØ§ÙŠÙ†ÙˆØ±Ø¯",
    "Benfica": "Ø¨Ù†ÙÙŠÙƒØ§", "Porto": "Ø¨ÙˆØ±ØªÙˆ", "Sporting CP": "Ø³Ø¨ÙˆØ±ØªÙŠÙ†Øº Ù„Ø´Ø¨ÙˆÙ†Ø©", "Sporting": "Ø³Ø¨ÙˆØ±ØªÙŠÙ†Øº Ù„Ø´Ø¨ÙˆÙ†Ø©",
}

# Ø¹ÙƒØ³ Ø§Ù„Ù‚Ø§Ù…ÙˆØ³
AR2EN = {v: k for k, v in EN2AR.items()}

def translate_en_to_ar(name: str) -> str:
    if not name: return ""
    if name in EN2AR: return EN2AR[name]
    if GoogleTranslator:
        try:
            return (GoogleTranslator(source="en", target="ar").translate(name) or name).strip()
        except Exception:
            return name
    return name

def translate_ar_to_en(name: str) -> str:
    if not name: return ""
    if name in AR2EN: return AR2EN[name]
    if GoogleTranslator:
        try:
            return (GoogleTranslator(source="ar", target="en").translate(name) or name).strip()
        except Exception:
            return name
    return name

# ===== parsing =====
def parse_title_to_teams_generic(title: str) -> tuple[str | None, str | None]:
    if not title:
        return None, None
    t = title.strip()
    DELIMS = [
        r"\s+v(?:s)?\.?\s+",
        r"\s+-\s+", r"\s+â€“\s+", r"\s+â€”\s+",
        r"\s*:\s*", r"\s*\|\s*", r"\s*Â·\s*", r"\s*;\s*",
    ]
    for d in DELIMS:
        parts = re.split(d, t, maxsplit=1)
        if len(parts) == 2:
            left, right = parts[0].strip(), parts[1].strip()
            if left and right:
                return left, right
    return None, None

def extract_liveonsat_match_teams(m: dict) -> tuple[str | None, str | None]:
    home = (m.get("home") or m.get("home_team"))
    away = (m.get("away") or m.get("away_team"))
    if home and away:
        return str(home).strip(), str(away).strip()
    title = (m.get("title") or "").strip()
    return parse_title_to_teams_generic(title)

# ===== Ø¨Ù†Ø§Ø¡ liveonsat entries Ø¨Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø© ÙÙ‚Ø· =====
def build_liveonsat_entries(live_data: dict):
    entries = []
    matches = (live_data or {}).get("matches", []) or []
    for m in matches:
        h_en, a_en = extract_liveonsat_match_teams(m)
        if not h_en or not a_en:
            continue

        # Ù‚Ù†ÙˆØ§Øª Ù…Ù† Ø¹Ø¯Ø© Ø­Ù‚ÙˆÙ„
        raw_channels = []
        for ck in ("channels_raw","channels","tv_channels","broadcasters","broadcaster"):
            if ck in m and m[ck]:
                raw = m[ck]
                if isinstance(raw, list):
                    raw_channels.extend([str(x) for x in raw])
                elif isinstance(raw, str):
                    raw_channels.extend(to_list_channels(raw))

        filtered = []
        for ch in raw_channels:
            ch = clean_channel_display(ch)
            if not ch: continue
            if is_bein_channel(ch):  # beIN Ù…Ù† ÙŠÙ„Ø§ ÙÙ‚Ø·
                continue
            if is_supported_channel(ch):
                filtered.append(ch)
        filtered = unique_preserving(filtered)
        if filtered:
            entries.append({
                "home_en": str(h_en).strip(),
                "away_en": str(a_en).strip(),
                "home_ar": translate_en_to_ar(str(h_en).strip()),
                "away_ar": translate_en_to_ar(str(a_en).strip()),
                "channels": filtered
            })
    return entries

# ===== Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ØµØ§Ø±Ù…Ø© Ø¨Ø¹Ø¯ Ø§Ù„ØªØ±Ø¬Ù…Ø© =====
def equal_norm(a: str, b: str) -> bool:
    return normalize_text(a) == normalize_text(b)

def match_channels_strict(home_ar_y: str, away_ar_y: str, lons_entries: list) -> list:
    """
    ÙŠØ·Ø§Ø¨Ù‚ ØµØ§Ø±Ù…Ù‹Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ±Ø¬Ù…Ø©:
      - Ù†Ù‚Ø§Ø±Ù†:
        1) AR_yalla == (EN_live â†’ AR)  Ù„ÙƒÙ„ Ù…Ù† home/away (ÙˆØ§Ù„Ø¹ÙƒØ³ Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨)
        2) (AR_yalla â†’ EN) == EN_live   Ù„ÙƒÙ„ Ù…Ù† home/away (ÙˆØ§Ù„Ø¹ÙƒØ³ Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨)
    Ø£ÙŠ ØªØ·Ø§Ø¨Ù‚ ÙƒØ§Ù…Ù„ ÙŠÙÙ‚Ø¨Ù„.
    """
    if not home_ar_y or not away_ar_y:
        return []

    # ØªØ±Ø¬Ù…Ø§Øª yalla->EN Ù…Ø±Ù‘Ø© ÙˆØ­Ø¯Ø©
    home_en_y = translate_ar_to_en(home_ar_y)
    away_en_y = translate_ar_to_en(away_ar_y)

    out = []
    for e in lons_entries:
        h_en = e["home_en"]; a_en = e["away_en"]
        h_ar = e["home_ar"]; a_ar = e["away_ar"]

        # Ø´Ø±Ø· A: Ù‚Ø§Ø±Ù† Ø¹Ø±Ø¨ÙŠ Ù„Ø¹Ø±Ø¨ÙŠ (EN_live Ù…ØªØ±Ø¬Ù… Ù„Ù„Ø¹Ø±Ø¨ÙŠ)
        a_ok = equal_norm(home_ar_y, h_ar) and equal_norm(away_ar_y, a_ar)
        b_ok = equal_norm(home_ar_y, a_ar) and equal_norm(away_ar_y, h_ar)

        # Ø´Ø±Ø· B: Ù‚Ø§Ø±Ù† Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ (yalla Ù…ØªØ±Ø¬Ù… Ù„Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ)
        c_ok = equal_norm(home_en_y, h_en) and equal_norm(away_en_y, a_en)
        d_ok = equal_norm(home_en_y, a_en) and equal_norm(away_en_y, h_en)

        if a_ok or b_ok or c_ok or d_ok:
            out.extend(e["channels"])

    return unique_preserving(out)

# ===== Ù‚Ù†ÙˆØ§Øª ÙŠÙ„Ø§ Ø´ÙˆØª =====
def collect_yalla_channels(yalla_match: dict) -> list:
    keys_try = ["channels_raw","channels","tv_channels","channel","channel_ar","channel_en","broadcasters","broadcaster"]
    out = []
    for k in keys_try:
        if k in yalla_match:
            out.extend(to_list_channels(yalla_match.get(k)))
    return unique_preserving(out)

def pick_primary_yalla_channel(chs: list[str]) -> str | None:
    if not chs:
        return None
    for c in chs:
        if is_bein_channel(c):
            return c.strip()
    return chs[0].strip()

# ===== Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ =====
def filter_matches():
    # 1) ÙŠÙ„Ø§ Ø´ÙˆØª
    try:
        yresp = requests.get(YALLASHOOT_URL, timeout=25)
        yresp.raise_for_status()
        yalla = yresp.json()
    except Exception as e:
        print(f"[x] ERROR fetching yallashoot: {e}")
        return

    yalla_matches = (yalla or {}).get("matches", []) or []
    if not yalla_matches:
        print("[!] yallashoot empty.")
        with OUTPUT_PATH.open("w", encoding="utf-8") as f:
            json.dump({"date": yalla.get("date"), "source_url": YALLASHOOT_URL, "matches": []}, f, ensure_ascii=False, indent=2)
        return

    # 2) liveonsat Ù…Ø­Ù„ÙŠ
    try:
        with INPUT_PATH.open("r", encoding="utf-8") as f:
            live_data = json.load(f)
    except Exception as e:
        print(f"[!] WARNING reading liveonsat: {e}")
        live_data = {}

    lons_entries = build_liveonsat_entries(live_data)

    # 3) Ø¯Ù…Ø¬
    out_matches = []
    used_extra = 0
    for m in yalla_matches:
        home_ar = (m.get("home") or m.get("home_team") or "").strip()
        away_ar = (m.get("away") or m.get("away_team") or "").strip()
        if not home_ar or not away_ar:
            continue

        # Ù‚Ù†Ø§Ø© Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ù† ÙŠÙ„Ø§
        y_chs = collect_yalla_channels(m)
        primary = pick_primary_yalla_channel(y_chs)
        yalla_only = [primary] if primary else []

        # Ù‚Ù†ÙˆØ§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù…Ù† liveonsat Ø¹Ø¨Ø± Ù…Ø·Ø§Ø¨Ù‚Ø© ØµØ§Ø±Ù…Ø© Ø¨Ø¹Ø¯ Ø§Ù„ØªØ±Ø¬Ù…Ø©
        extra = match_channels_strict(home_ar, away_ar, lons_entries)
        if extra:
            used_extra += 1

        channels = unique_preserving([*yalla_only, *extra])

        new_entry = {
            "competition": m.get("competition") or m.get("league") or m.get("tournament"),
            "kickoff_baghdad": m.get("kickoff_baghdad") or m.get("time_baghdad") or m.get("kickoff"),
            "home_team": home_ar,
            "away_team": away_ar,
            "channels_raw": channels,
            "home_logo": m.get("home_logo"),
            "away_logo": m.get("away_logo"),
            "status_text": m.get("status_text"),
            "result_text": m.get("result_text"),
        }
        out_matches.append(new_entry)

    with OUTPUT_PATH.open("w", encoding="utf-8") as f:
        json.dump({"date": yalla.get("date"), "source_url": YALLASHOOT_URL, "matches": out_matches}, f, ensure_ascii=False, indent=2)

    print(f"[âœ“] Done. Matches: {len(out_matches)} | Added-extra-from-liveonsat: {used_extra}")
    if GoogleTranslator is None:
        print("[!] deep-translator not installed â€” fallback to dictionary only.")

if __name__ == "__main__":
    filter_matches()
