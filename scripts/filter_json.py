# scripts/filter_json.py
# -*- coding: utf-8 -*-
import json
import re
import unicodedata
from pathlib import Path
import requests

# ==== Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª/Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª (Ù†ÙØ³Ù‡Ø§) ====
REPO_ROOT = Path(__file__).resolve().parents[1]
MATCHES_DIR = REPO_ROOT / "matches"
INPUT_PATH = MATCHES_DIR / "liveonsat_raw.json"        # Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
OUTPUT_PATH = MATCHES_DIR / "filtered_matches.json"
YALLASHOOT_URL = "https://raw.githubusercontent.com/a7shk1/yallashoot/refs/heads/main/matches/today.json"

# ==== Ø£Ø¯ÙˆØ§Øª Ù…Ø³Ø§Ø¹Ø¯Ø© ====
AR_LETTERS_RE = re.compile(r'[\u0600-\u06FF]')
EMOJI_MISC_RE = re.compile(r'[\u2600-\u27BF\U0001F300-\U0001FAFF]+')
BEIN_RE = re.compile(r'bein\s*sports?', re.I)

def strip_accents(s: str) -> str:
    return ''.join(c for c in unicodedata.normalize('NFKD', s) if not unicodedata.combining(c))

def normalize_text(text: str) -> str:
    if not text:
        return ""
    text = str(text)
    text = EMOJI_MISC_RE.sub('', text)
    text = re.sub(r'\(.*?\)', '', text)
    text = strip_accents(text)
    text = text.lower()
    text = text.replace("&", "and")
    text = re.sub(r'\b(fc|sc|cf|u\d+)\b', '', text)
    # Ø¨Ø¯Ø§Ø¦Ù„ Ø¹Ø±Ø¨ÙŠØ© Ø´Ø§Ø¦Ø¹Ø©
    text = (text
            .replace("Ø£", "Ø§").replace("Ø¥", "Ø§").replace("Ø¢", "Ø§")
            .replace("Ù‰", "ÙŠ").replace("Ø©", "Ù‡").replace("Ø§Ù„", "")
            .replace("Ù€", ""))
    text = text.replace(" ", "").replace("-", "").replace("_", "")
    text = re.sub(r'[^a-z0-9\u0600-\u06FF]', '', text)
    return text.strip()

def unique_preserving(seq):
    seen, out = set(), []
    for x in seq:
        k = str(x).lower().strip()
        if k not in seen:
            seen.add(k)
            out.append(x)
    return out

def to_list_channels(val):
    if isinstance(val, list):
        return [str(x).strip() for x in val if str(x).strip()]
    if isinstance(val, str):
        s = val.strip()
        if not s: return []
        parts = re.split(r"\s*(?:,|ØŒ|/|\||&| Ùˆ | and )\s*", s, flags=re.I)
        return [p for p in parts if p]
    return []

def clean_channel_display(name: str) -> str:
    if not name: return ""
    s = str(name)
    s = EMOJI_MISC_RE.sub("", s)
    s = re.sub(r"\s*\((?:\$?\/?geo\/?R|geo\/?R|\$\/?geo)\)\s*", "", s, flags=re.I)
    s = re.sub(r"ğŸ“º|\[online\]|\[app\]", "", s, flags=re.I)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def is_bein_channel(name: str) -> bool:
    return bool(BEIN_RE.search(name or ""))

# ==== Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø© ÙÙ‚Ø· ====
SUPPORTED_CHANNELS = [
    "MATCH! Futbol 1", "MATCH! Futbol 2", "MATCH! Futbol 3",
    "Football HD",
    "Sport TV1 Portugal HD", "Sport TV2 Portugal HD",
    "ESPN 1 Brazil", "ESPN 2 Brazil", "ESPN 3 Brazil", "ESPN 4 Brazil", "ESPN 5 Brazil", "ESPN 6 Brazil", "ESPN 7 Brazil",
    "DAZN 1 Portugal HD", "DAZN 2 Portugal HD", "DAZN 3 Portugal HD", "DAZN 4 Portugal HD", "DAZN 5 Portugal HD", "DAZN 6 Portugal HD",
    "MATCH! Premier HD", "Sky Sports Main Event HD", "Sky Sport Premier League HD", "IRIB Varzesh HD",
    "Persiana Sport HD", "MBC Action HD", "TNT Sports 1 HD", "TNT Sports 2 HD", "TNT Sports HD",
    "MBC masrHD", "MBC masr2HD", "ssc1 hd", "ssc2 hd", "Shahid MBC",
]
_supported_tokens = set()
for c in SUPPORTED_CHANNELS:
    cl = c.lower()
    _supported_tokens.add(cl)
    _supported_tokens.add(cl.replace(" hd", ""))
SUPPORTED_TOKENS = list(_supported_tokens)

def is_supported_channel(name: str) -> bool:
    if not name: return False
    n = name.lower()
    return any(tok in n for tok in SUPPORTED_TOKENS)

# ==== Ù‚Ø§Ù…ÙˆØ³ ENâ†’AR Ù…ÙˆØ³Ù‘Ø¹ (Ø£Ù†Ø¯ÙŠØ© Ø¹Ø±Ø¨ÙŠØ©ØŒ Ø¢Ø³ÙŠÙˆÙŠØ©ØŒ Ø£ÙØ±ÙŠÙ‚ÙŠØ©ØŒ Ø£ÙˆØ±ÙˆØ¨ÙŠØ©ØŒ Ù…Ù†ØªØ®Ø¨Ø§Øª) ====
# (ØªÙ‚Ø¯Ø± ØªÙˆØ³Ù‘Ø¹Ù‡ Ù„Ø§Ø­Ù‚Ù‹Ø§ Ø¨Ø³Ù‡ÙˆÙ„Ø© â€” Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… Ø£ÙŠ ØªØ±Ø¬Ù…Ø© Ø¢Ù„ÙŠØ©)
EN2AR = {
    # Ù…Ù†ØªØ®Ø¨Ø§Øª Ø¹Ø±Ø¨ÙŠØ©
    "Iraq":"Ø§Ù„Ø¹Ø±Ø§Ù‚","Saudi Arabia":"Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©","Qatar":"Ù‚Ø·Ø±","United Arab Emirates":"Ø§Ù„Ø¥Ù…Ø§Ø±Ø§Øª","UAE":"Ø§Ù„Ø¥Ù…Ø§Ø±Ø§Øª",
    "Kuwait":"Ø§Ù„ÙƒÙˆÙŠØª","Bahrain":"Ø§Ù„Ø¨Ø­Ø±ÙŠÙ†","Oman":"Ø¹Ù…Ø§Ù†","Jordan":"Ø§Ù„Ø£Ø±Ø¯Ù†","Syria":"Ø³ÙˆØ±ÙŠØ§","Lebanon":"Ù„Ø¨Ù†Ø§Ù†",
    "Palestine":"ÙÙ„Ø³Ø·ÙŠÙ†","Yemen":"Ø§Ù„ÙŠÙ…Ù†","Egypt":"Ù…ØµØ±","Libya":"Ù„ÙŠØ¨ÙŠØ§","Tunisia":"ØªÙˆÙ†Ø³","Algeria":"Ø§Ù„Ø¬Ø²Ø§Ø¦Ø±","Morocco":"Ø§Ù„Ù…ØºØ±Ø¨",

    # Ù…Ù†ØªØ®Ø¨Ø§Øª Ø¹Ø§Ù„Ù…ÙŠØ© Ù…Ø®ØªØµØ±Ø©
    "Brazil":"Ø§Ù„Ø¨Ø±Ø§Ø²ÙŠÙ„","Argentina":"Ø§Ù„Ø£Ø±Ø¬Ù†ØªÙŠÙ†","Germany":"Ø£Ù„Ù…Ø§Ù†ÙŠØ§","France":"ÙØ±Ù†Ø³Ø§","Spain":"Ø¥Ø³Ø¨Ø§Ù†ÙŠØ§","Italy":"Ø¥ÙŠØ·Ø§Ù„ÙŠØ§",
    "England":"Ø¥Ù†Ø¬Ù„ØªØ±Ø§","Portugal":"Ø§Ù„Ø¨Ø±ØªØºØ§Ù„","Netherlands":"Ù‡ÙˆÙ„Ù†Ø¯Ø§","Belgium":"Ø¨Ù„Ø¬ÙŠÙƒØ§","Croatia":"ÙƒØ±ÙˆØ§ØªÙŠØ§","Uruguay":"Ø£ÙˆØ±ÙˆØ¬ÙˆØ§ÙŠ",
    "United States":"Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø©","USA":"Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø©","Mexico":"Ø§Ù„Ù…ÙƒØ³ÙŠÙƒ","Japan":"Ø§Ù„ÙŠØ§Ø¨Ø§Ù†","South Korea":"ÙƒÙˆØ±ÙŠØ§ Ø§Ù„Ø¬Ù†ÙˆØ¨ÙŠØ©","Australia":"Ø£Ø³ØªØ±Ø§Ù„ÙŠØ§",

    # Ø£Ù†Ø¯ÙŠØ© Ø³Ø¹ÙˆØ¯ÙŠØ©
    "Al Hilal":"Ø§Ù„Ù‡Ù„Ø§Ù„","Al-Hilal":"Ø§Ù„Ù‡Ù„Ø§Ù„","Al Nassr":"Ø§Ù„Ù†ØµØ±","Al-Nassr":"Ø§Ù„Ù†ØµØ±","Al Ittihad":"Ø§Ù„Ø§ØªØ­Ø§Ø¯","Al-Ittihad":"Ø§Ù„Ø§ØªØ­Ø§Ø¯",
    "Al Ahli":"Ø§Ù„Ø£Ù‡Ù„ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ","Al-Ahli":"Ø§Ù„Ø£Ù‡Ù„ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ","Al Shabab":"Ø§Ù„Ø´Ø¨Ø§Ø¨","Al-Shabab":"Ø§Ù„Ø´Ø¨Ø§Ø¨","Al Ettifaq":"Ø§Ù„Ø§ØªÙØ§Ù‚","Al-Ettifaq":"Ø§Ù„Ø§ØªÙØ§Ù‚",
    "Al Fayha":"Ø§Ù„ÙÙŠØ­Ø§Ø¡","Al-Fayha":"Ø§Ù„ÙÙŠØ­Ø§Ø¡","Al Raed":"Ø§Ù„Ø±Ø§Ø¦Ø¯","Al-Raed":"Ø§Ù„Ø±Ø§Ø¦Ø¯","Al Taawoun":"Ø§Ù„ØªØ¹Ø§ÙˆÙ†","Al-Taawoun":"Ø§Ù„ØªØ¹Ø§ÙˆÙ†",
    "Abha":"Ø£Ø¨Ù‡Ø§","Damac":"Ø¶Ù…Ùƒ","Al Fateh":"Ø§Ù„ÙØªØ­","Al-Fateh":"Ø§Ù„ÙØªØ­","Al Okhdood":"Ø§Ù„Ø£Ø®Ø¯ÙˆØ¯","Al-Okhdood":"Ø§Ù„Ø£Ø®Ø¯ÙˆØ¯",
    "Al Riyadh":"Ø§Ù„Ø±ÙŠØ§Ø¶","Al-Riyadh":"Ø§Ù„Ø±ÙŠØ§Ø¶","Al Wehda":"Ø§Ù„ÙˆØ­Ø¯Ø©","Al-Wehda":"Ø§Ù„ÙˆØ­Ø¯Ø©","Al Qadsiah":"Ø§Ù„Ù‚Ø§Ø¯Ø³ÙŠØ©","Al-Qadsiah":"Ø§Ù„Ù‚Ø§Ø¯Ø³ÙŠØ©",

    # Ø£Ù†Ø¯ÙŠØ© Ù‚Ø·Ø±/Ø§Ù„Ø¥Ù…Ø§Ø±Ø§Øª/Ø§Ù„Ø¹Ø±Ø§Ù‚/Ø§Ù„Ù…ØºØ±Ø¨
    "Al Sadd":"Ø§Ù„Ø³Ø¯","Al-Sadd":"Ø§Ù„Ø³Ø¯","Al Duhail":"Ø§Ù„Ø¯Ø­ÙŠÙ„","Al-Duhail":"Ø§Ù„Ø¯Ø­ÙŠÙ„","Al Gharafa":"Ø§Ù„ØºØ±Ø§ÙØ©","Al-Gharafa":"Ø§Ù„ØºØ±Ø§ÙØ©",
    "Al Rayyan":"Ø§Ù„Ø±ÙŠØ§Ù†","Al-Rayyan":"Ø§Ù„Ø±ÙŠØ§Ù†","Qatar SC":"Ù‚Ø·Ø±","Al Arabi":"Ø§Ù„Ø¹Ø±Ø¨ÙŠ","Al-Arabi":"Ø§Ù„Ø¹Ø±Ø¨ÙŠ","Al Wakrah":"Ø§Ù„ÙˆÙƒØ±Ø©","Al-Wakrah":"Ø§Ù„ÙˆÙƒØ±Ø©",
    "Al Ain":"Ø§Ù„Ø¹ÙŠÙ†","Al-Ain":"Ø§Ù„Ø¹ÙŠÙ†","Al Jazira":"Ø§Ù„Ø¬Ø²ÙŠØ±Ø©","Al-Jazira":"Ø§Ù„Ø¬Ø²ÙŠØ±Ø©","Shabab Al Ahli":"Ø´Ø¨Ø§Ø¨ Ø§Ù„Ø£Ù‡Ù„ÙŠ",
    "Al Nasr Dubai":"Ø§Ù„Ù†ØµØ± Ø§Ù„Ø¥Ù…Ø§Ø±Ø§ØªÙŠ","Sharjah":"Ø§Ù„Ø´Ø§Ø±Ù‚Ø©","Khor Fakkan":"Ø®ÙˆØ±ÙÙƒØ§Ù†","Bani Yas":"Ø¨Ù†ÙŠ ÙŠØ§Ø³",
    "Al Shorta":"Ø§Ù„Ø´Ø±Ø·Ø©","Al-Shorta":"Ø§Ù„Ø´Ø±Ø·Ø©","Al Zawraa":"Ø§Ù„Ø²ÙˆØ±Ø§Ø¡","Al-Zawraa":"Ø§Ù„Ø²ÙˆØ±Ø§Ø¡",
    "Al Quwa Al Jawiya":"Ø§Ù„Ù‚ÙˆØ© Ø§Ù„Ø¬ÙˆÙŠØ©","Al-Quwa Al-Jawiya":"Ø§Ù„Ù‚ÙˆØ© Ø§Ù„Ø¬ÙˆÙŠØ©","Naft Al Wasat":"Ù†ÙØ· Ø§Ù„ÙˆØ³Ø·","Al Najaf":"Ø§Ù„Ù†Ø¬Ù",
    "Erbil":"Ø£Ø±Ø¨ÙŠÙ„","Duhok":"Ø¯Ù‡ÙˆÙƒ","Al Minaa":"Ø§Ù„Ù…ÙŠÙ†Ø§Ø¡","Al-Minaa":"Ø§Ù„Ù…ÙŠÙ†Ø§Ø¡",
    "Wydad":"Ø§Ù„ÙˆØ¯Ø§Ø¯","Raja":"Ø§Ù„Ø±Ø¬Ø§Ø¡","FUS Rabat":"Ø§Ù„ÙØªØ­ Ø§Ù„Ø±Ø¨Ø§Ø·ÙŠ","RS Berkane":"Ù†Ù‡Ø¶Ø© Ø¨Ø±ÙƒØ§Ù†",
    "Hassania Agadir":"Ø­Ø³Ù†ÙŠØ© Ø£ÙƒØ§Ø¯ÙŠØ±","Ittihad Tanger":"Ø§ØªØ­Ø§Ø¯ Ø·Ù†Ø¬Ø©","OC Safi":"Ø£ÙˆÙ„Ù…Ø¨ÙŠÙƒ Ø¢Ø³ÙÙŠ","Olympic Safi":"Ø£ÙˆÙ„Ù…Ø¨ÙŠÙƒ Ø¢Ø³ÙÙŠ",

    # Ø¥Ø³Ø¨Ø§Ù†ÙŠØ§/Ø¥ÙŠØ·Ø§Ù„ÙŠØ§/Ø¥Ù†Ø¬Ù„ØªØ±Ø§/ÙØ±Ù†Ø³Ø§/Ø£Ù„Ù…Ø§Ù†ÙŠØ§ (Ø£Ø´Ù‡Ø±)
    "Real Madrid":"Ø±ÙŠØ§Ù„ Ù…Ø¯Ø±ÙŠØ¯","Barcelona":"Ø¨Ø±Ø´Ù„ÙˆÙ†Ø©","Atletico Madrid":"Ø£ØªÙ„ØªÙŠÙƒÙˆ Ù…Ø¯Ø±ÙŠØ¯","Sevilla":"Ø¥Ø´Ø¨ÙŠÙ„ÙŠØ©","Valencia":"ÙØ§Ù„Ù†Ø³ÙŠØ§",
    "Villarreal":"ÙÙŠØ§Ø±ÙŠØ§Ù„","Real Sociedad":"Ø±ÙŠØ§Ù„ Ø³ÙˆØ³ÙŠØ¯Ø§Ø¯","Espanyol":"Ø¥Ø³Ø¨Ø§Ù†ÙŠÙˆÙ„","Real Mallorca":"Ø±ÙŠØ§Ù„ Ù…Ø§ÙŠÙˆØ±ÙƒØ§","Mallorca":"Ø±ÙŠØ§Ù„ Ù…Ø§ÙŠÙˆØ±ÙƒØ§",

    "Inter":"Ø¥Ù†ØªØ± Ù…ÙŠÙ„Ø§Ù†","Inter Milan":"Ø¥Ù†ØªØ± Ù…ÙŠÙ„Ø§Ù†","AC Milan":"Ù…ÙŠÙ„Ø§Ù†","Milan":"Ù…ÙŠÙ„Ø§Ù†","Juventus":"ÙŠÙˆÙÙ†ØªÙˆØ³",
    "Napoli":"Ù†Ø§Ø¨ÙˆÙ„ÙŠ","Roma":"Ø±ÙˆÙ…Ø§","Lazio":"Ù„Ø§ØªØ³ÙŠÙˆ","Fiorentina":"ÙÙŠÙˆØ±Ù†ØªÙŠÙ†Ø§","Atalanta":"Ø£ØªØ§Ù„Ø§Ù†ØªØ§","Torino":"ØªÙˆØ±ÙŠÙ†Ùˆ",
    "Udinese":"Ø£ÙˆØ¯ÙŠÙ†ÙŠØ²ÙŠ","Sassuolo":"Ø³Ø§Ø³ÙˆÙ„Ùˆ","Monza":"Ù…ÙˆÙ†Ø²Ø§","Como":"ÙƒÙˆÙ…Ùˆ","Genoa":"Ø¬Ù†ÙˆÙ‰","Hellas Verona":"Ù‡ÙŠÙ„Ø§Ø³ ÙÙŠØ±ÙˆÙ†Ø§","Cremonese":"ÙƒØ±ÙŠÙ…ÙˆÙ†ÙŠØ²ÙŠ",

    "Manchester City":"Ù…Ø§Ù†Ø´Ø³ØªØ± Ø³ÙŠØªÙŠ","Manchester United":"Ù…Ø§Ù†Ø´Ø³ØªØ± ÙŠÙˆÙ†Ø§ÙŠØªØ¯","Arsenal":"Ø£Ø±Ø³Ù†Ø§Ù„","Liverpool":"Ù„ÙŠÙØ±Ø¨ÙˆÙ„","Chelsea":"ØªØ´ÙŠÙ„Ø³ÙŠ",
    "Tottenham Hotspur":"ØªÙˆØªÙ†Ù‡Ø§Ù…","Tottenham":"ØªÙˆØªÙ†Ù‡Ø§Ù…","Newcastle United":"Ù†ÙŠÙˆÙƒØ§Ø³Ù„ ÙŠÙˆÙ†Ø§ÙŠØªØ¯","Aston Villa":"Ø£Ø³ØªÙˆÙ† ÙÙŠÙ„Ø§",
    "West Ham United":"ÙˆØ³Øª Ù‡Ø§Ù… ÙŠÙˆÙ†Ø§ÙŠØªØ¯","Everton":"Ø¥ÙŠÙØ±ØªÙˆÙ†","Wolverhampton":"ÙˆÙ„ÙØ±Ù‡Ø§Ù…Ø¨ØªÙˆÙ†","Wolves":"ÙˆÙ„ÙØ±Ù‡Ø§Ù…Ø¨ØªÙˆÙ†",

    "Paris Saint-Germain":"Ø¨Ø§Ø±ÙŠØ³ Ø³Ø§Ù† Ø¬ÙŠØ±Ù…Ø§Ù†","PSG":"Ø¨Ø§Ø±ÙŠØ³ Ø³Ø§Ù† Ø¬ÙŠØ±Ù…Ø§Ù†","Marseille":"Ù…Ø§Ø±Ø³ÙŠÙ„ÙŠØ§","Lyon":"Ù„ÙŠÙˆÙ†","Monaco":"Ù…ÙˆÙ†Ø§ÙƒÙˆ",
    "Lille":"Ù„ÙŠÙ„","Nice":"Ù†ÙŠØ³","Rennes":"Ø±ÙŠÙ†","Brest":"Ø¨Ø±ÙŠØ³Øª","Strasbourg":"Ø³ØªØ±Ø§Ø³Ø¨ÙˆØ±Øº","Montpellier":"Ù…ÙˆÙ†Ø¨Ù„ÙŠÙŠÙ‡","Guingamp":"Ø¬Ø§Ù†Ø¬ÙˆÙ†",

    "Bayern Munich":"Ø¨Ø§ÙŠØ±Ù† Ù…ÙŠÙˆÙ†Ø®","Borussia Dortmund":"Ø¨ÙˆØ±ÙˆØ³ÙŠØ§ Ø¯ÙˆØ±ØªÙ…ÙˆÙ†Ø¯","RB Leipzig":"Ù„Ø§ÙŠØ¨Ø²ÙŠØº","Bayer Leverkusen":"Ø¨Ø§ÙŠØ± Ù„ÙŠÙØ±ÙƒÙˆØ²Ù†",

    # Ù‡ÙˆÙ„Ù†Ø¯Ø§/Ø§Ù„Ø¨Ø±ØªØºØ§Ù„
    "Ajax":"Ø£ÙŠØ§ÙƒØ³","PSV Eindhoven":"Ø¢ÙŠÙ†Ø¯Ù‡ÙˆÙÙ†","Feyenoord":"ÙØ§ÙŠÙ†ÙˆØ±Ø¯",
    "Benfica":"Ø¨Ù†ÙÙŠÙƒØ§","Porto":"Ø¨ÙˆØ±ØªÙˆ","Sporting CP":"Ø³Ø¨ÙˆØ±ØªÙŠÙ†Øº Ù„Ø´Ø¨ÙˆÙ†Ø©","Sporting":"Ø³Ø¨ÙˆØ±ØªÙŠÙ†Øº Ù„Ø´Ø¨ÙˆÙ†Ø©",
}
AR2EN = {v: k for k, v in EN2AR.items()}

def en_to_ar(name: str) -> str:
    return EN2AR.get(name, name or "")

def ar_to_en(name: str) -> str:
    return AR2EN.get(name, name or "")

# ==== parsing liveonsat ====
def parse_title_to_teams_generic(title: str) -> tuple[str|None, str|None]:
    if not title: return None, None
    t = title.strip()
    DELIMS = [
        r"\s+v(?:s)?\.?\s+",  # v / vs
        r"\s+-\s+", r"\s+â€“\s+", r"\s+â€”\s+",
        r"\s*:\s*", r"\s*\|\s*", r"\s*Â·\s*", r"\s*;\s*",
    ]
    for d in DELIMS:
        parts = re.split(d, t, maxsplit=1)
        if len(parts) == 2:
            l, r = parts[0].strip(), parts[1].strip()
            if l and r:
                return l, r
    return None, None

def extract_live_match(m: dict) -> tuple[str|None, str|None]:
    home = (m.get("home") or m.get("home_team"))
    away = (m.get("away") or m.get("away_team"))
    if home and away:
        return str(home).strip(), str(away).strip()
    title = (m.get("title") or "").strip()
    return parse_title_to_teams_generic(title)

# ==== Ø¨Ù†Ø§Ø¡ ÙÙ‡Ø±Ø³ liveonsat Ø¨Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø© ====
def build_live_entries(live_data: dict):
    out = []
    matches = (live_data or {}).get("matches", []) or []
    for m in matches:
        h_en, a_en = extract_live_match(m)
        if not h_en or not a_en:
            continue

        # Ù‚Ù†ÙˆØ§Øª Ù…Ù† Ø¹Ø¯Ø© Ø­Ù‚ÙˆÙ„
        raw_channels = []
        for ck in ("channels_raw","channels","tv_channels","broadcasters","broadcaster"):
            if ck in m and m[ck]:
                raw = m[ck]
                if isinstance(raw, list):
                    raw_channels.extend([str(x) for x in raw])
                elif isinstance(raw, str):
                    raw_channels.extend(to_list_channels(raw))

        # ÙÙ„ØªØ±Ø© Ø§Ù„Ù‚Ù†ÙˆØ§Øª
        filtered = []
        for ch in raw_channels:
            ch = clean_channel_display(ch)
            if not ch: continue
            if is_bein_channel(ch):  # beIN Ù…Ù† ÙŠÙ„Ø§ ÙÙ‚Ø·
                continue
            if is_supported_channel(ch):
                filtered.append(ch)
        filtered = unique_preserving(filtered)
        if not filtered:
            continue

        entry = {
            "competition": m.get("competition") or "",
            "kickoff_baghdad": m.get("kickoff_baghdad") or m.get("time_baghdad") or m.get("kickoff") or "",
            "home_en": h_en.strip(),
            "away_en": a_en.strip(),
            "home_ar_guess": en_to_ar(h_en.strip()),
            "away_ar_guess": en_to_ar(a_en.strip()),
            "channels": filtered,
        }
        out.append(entry)
    return out

# ==== ÙŠÙ„Ø§ Ø´ÙˆØª ====
def collect_yalla_channels(y: dict) -> list:
    keys_try = ["channels_raw","channels","tv_channels","channel","channel_ar","channel_en","broadcasters","broadcaster"]
    out = []
    for k in keys_try:
        if k in y:
            out.extend(to_list_channels(y.get(k)))
    return unique_preserving(out)

def pick_primary_yalla_channel(chs: list[str]) -> str|None:
    if not chs: return None
    for c in chs:
        if is_bein_channel(c):
            return c.strip()
    return chs[0].strip()

def build_yalla_index(yalla_data: dict):
    """
    ÙÙ‡Ø±Ø³ Ø¨Ù…ÙØ§ØªÙŠØ­:
      - AR pair: norm(home_ar)-norm(away_ar)
      - EN pair: norm(ar_to_en(home_ar))-norm(ar_to_en(away_ar))
    ÙˆÙ†Ø®Ø²Ù† ÙƒÙ„Ø§ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ÙŠÙ† (home-away) Ùˆ(away-home).
    """
    idx = {}
    matches = (yalla_data or {}).get("matches", []) or []
    for m in matches:
        home_ar = (m.get("home") or m.get("home_team") or "").strip()
        away_ar = (m.get("away") or m.get("away_team") or "").strip()
        if not home_ar or not away_ar:
            continue

        # Ù…ÙØ§ØªÙŠØ­ Ø¹Ø±Ø¨ÙŠØ© Ù…Ø¨Ø§Ø´Ø±Ø©
        k1 = f"{normalize_text(home_ar)}-{normalize_text(away_ar)}"
        k2 = f"{normalize_text(away_ar)}-{normalize_text(home_ar)}"

        # Ù…ÙØ§ØªÙŠØ­ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù…Ù† ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (Ù…Ù† Ø§Ù„Ù‚Ø§Ù…ÙˆØ³)
        home_en = ar_to_en(home_ar)
        away_en = ar_to_en(away_ar)
        k3 = f"{normalize_text(home_en)}-{normalize_text(away_en)}"
        k4 = f"{normalize_text(away_en)}-{normalize_text(home_en)}"

        for k in (k1, k2, k3, k4):
            # Ù†Ø®Ø²Ù† Ø£ÙØ¶Ù„ Ù‚Ù†Ø§Ø© Ù…Ù† ÙŠÙ„Ø§
            y_chs = collect_yalla_channels(m)
            primary = pick_primary_yalla_channel(y_chs)
            idx[k] = {
                "match": m,
                "primary_yalla_channel": primary
            }
    return idx

# ==== Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ØµØ§Ø±Ù…Ø© (Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­ÙˆÙŠÙ„) ====
def match_live_to_yalla(live_entry: dict, y_idx: dict) -> dict|None:
    # 1) Ø¬Ø±Ù‘Ø¨ Ù…Ù‚Ø§Ø±Ù†Ø© Ø¹Ø±Ø¨ÙŠ Ù„Ø¹Ø±Ø¨ÙŠ (EN_liveâ†’AR) Ø¨Ø§Ù„Ø§ØªØ¬Ø§Ù‡ÙŠÙ†
    h_ar = live_entry["home_ar_guess"]
    a_ar = live_entry["away_ar_guess"]
    if h_ar and a_ar:
        k1 = f"{normalize_text(h_ar)}-{normalize_text(a_ar)}"
        k2 = f"{normalize_text(a_ar)}-{normalize_text(h_ar)}"
        if k1 in y_idx: return y_idx[k1]
        if k2 in y_idx: return y_idx[k2]

    # 2) Ø¬Ø±Ù‘Ø¨ Ù…Ù‚Ø§Ø±Ù†Ø© Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ (AR_yallaâ†’EN) Ø¨Ø§Ù„Ø§ØªØ¬Ø§Ù‡ÙŠÙ† â€” ÙŠØªÙ… Ù…Ù† Ø®Ù„Ø§Ù„ ÙÙ‡Ø±Ø³ y_idx
    h_en = live_entry["home_en"]; a_en = live_entry["away_en"]
    k3 = f"{normalize_text(h_en)}-{normalize_text(a_en)}"
    k4 = f"{normalize_text(a_en)}-{normalize_text(h_en)}"
    if k3 in y_idx: return y_idx[k3]
    if k4 in y_idx: return y_idx[k4]

    return None

# ==== Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ====
def filter_matches():
    # 0) Ø§Ù‚Ø±Ø£ liveonsat (Ù…ØµØ¯Ø± Ø£Ø³Ø§Ø³ÙŠ)
    try:
        with INPUT_PATH.open("r", encoding="utf-8") as f:
            live_data = json.load(f)
    except Exception as e:
        print(f"[x] ERROR reading liveonsat: {e}")
        return

    live_entries = build_live_entries(live_data)
    if not live_entries:
        print("[!] liveonsat has 0 usable matches (after channel filtering).")
        with OUTPUT_PATH.open("w", encoding="utf-8") as f:
            json.dump({"date": live_data.get("date"), "source_url": live_data.get("source_url"), "matches": []}, f, ensure_ascii=False, indent=2)
        return

    # 1) Ø­Ù…Ù‘Ù„ ÙŠÙ„Ø§ Ø´ÙˆØª (Ù„Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© + beIN)
    try:
        yresp = requests.get(YALLASHOOT_URL, timeout=25)
        yresp.raise_for_status()
        yalla = yresp.json()
    except Exception as e:
        print(f"[x] ERROR fetching yallashoot: {e}")
        yalla = {"matches": []}

    y_idx = build_yalla_index(yalla)

    # 2) ØªÙ‚Ø§Ø·Ø¹ + Ø¯Ù…Ø¬
    out_matches = []
    matched_cnt = 0
    for le in live_entries:
        m_y = match_live_to_yalla(le, y_idx)
        if not m_y:
            continue
        matched_cnt += 1

        y_match = m_y["match"]
        primary_yalla = m_y.get("primary_yalla_channel")

        # Ù‚Ù†ÙˆØ§Øª: beIN Ù…Ù† ÙŠÙ„Ø§ (Ø¥Ù† ÙˆØ¬ÙØ¯Øª) + Ù‚Ù†ÙˆØ§Øª liveonsat Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø©
        channels = []
        if primary_yalla:
            channels.append(primary_yalla)
        channels.extend(le["channels"])
        channels = unique_preserving(channels)

        # Ø§Ù„Ø­Ù‚ÙˆÙ„
        out = {
            "competition": y_match.get("competition") or le["competition"],
            "kickoff_baghdad": y_match.get("kickoff_baghdad") or le["kickoff_baghdad"],
            "home_team": en_to_ar(le["home_en"]) if en_to_ar(le["home_en"]) else le["home_en"],
            "away_team": en_to_ar(le["away_en"]) if en_to_ar(le["away_en"]) else le["away_en"],
            "channels_raw": channels,
            "home_logo": y_match.get("home_logo"),
            "away_logo": y_match.get("away_logo"),
            "status_text": y_match.get("status_text"),
            "result_text": y_match.get("result_text"),
        }
        out_matches.append(out)

    # 3) ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª
    output = {
        "date": live_data.get("date") or yalla.get("date"),
        "source_url": live_data.get("source_url") or "liveonsat + yallashoot",
        "matches": out_matches
    }
    with OUTPUT_PATH.open("w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"[âœ“] Done. live entries: {len(live_entries)} | matched with yalla: {matched_cnt} | written: {len(out_matches)}")

if __name__ == "__main__":
    filter_matches()
