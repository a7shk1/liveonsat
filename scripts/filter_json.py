# scripts/filter_json.py
# -*- coding: utf-8 -*-
import json
import re
import unicodedata
from pathlib import Path
import requests
from datetime import datetime

# ==== Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª/Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ====
REPO_ROOT = Path(__file__).resolve().parents[1]
MATCHES_DIR = REPO_ROOT / "matches"
INPUT_PATH_LIVE = MATCHES_DIR / "liveonsat_raw.json"     # Ù…ØµØ¯Ø± Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ© (EN)
OUTPUT_PATH = MATCHES_DIR / "filtered_matches.json"      # Ø§Ù„Ù†Ø§ØªØ¬
YALLASHOOT_URL = "https://raw.githubusercontent.com/a7shk1/yallashoot/refs/heads/main/matches/today.json"

# ==== Ø£Ø¯ÙˆØ§Øª Ù…Ø³Ø§Ø¹Ø¯Ø© Ø¹Ø§Ù…Ø© ====
EMOJI_MISC_RE = re.compile(r'[\u2600-\u27BF\U0001F300-\U0001FAFF]+')
BEIN_RE = re.compile(r'bein\s*sports?', re.I)
TIME_RE = re.compile(r'^(\d{1,2}):(\d{2})$')

def strip_accents(s: str) -> str:
    return ''.join(c for c in unicodedata.normalize('NFKD', s) if not unicodedata.combining(c))

def normalize_text(text: str) -> str:
    """ØªØ·Ø¨ÙŠØ¹ Ù‚ÙˆÙŠ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨Ø§Ù„Ù…ÙØ§ØªÙŠØ­/Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©/Ø§Ù„ÙÙ„Ø§ØªØ± Ø§Ù„Ø¬Ø²Ø¦ÙŠØ©."""
    if not text:
        return ""
    text = str(text)
    text = EMOJI_MISC_RE.sub('', text)
    text = re.sub(r'\(.*?\)', '', text)
    text = strip_accents(text)
    text = text.lower()
    text = text.replace("&", "and")
    text = re.sub(r'\b(fc|sc|cf|u\d+)\b', '', text)
    # Ø¨Ø¯Ø§Ø¦Ù„ Ø¹Ø±Ø¨ÙŠØ© Ø´Ø§Ø¦Ø¹Ø©
    text = (text
            .replace("Ø£", "Ø§").replace("Ø¥", "Ø§").replace("Ø¢", "Ø§")
            .replace("Ù‰", "ÙŠ").replace("Ø©", "Ù‡").replace("Ø§Ù„", "")
            .replace("Ù€", ""))
    text = text.replace(" ", "").replace("-", "").replace("_", "")
    text = re.sub(r'[^a-z0-9\u0600-\u06FF]', '', text)
    return text.strip()

def unique_preserving(seq):
    seen, out = set(), []
    for x in seq:
        k = str(x).lower().strip()
        if k not in seen:
            seen.add(k)
            out.append(x)
    return out

def to_list_channels(val):
    if isinstance(val, list):
        return [str(x).strip() for x in val if str(x).strip()]
    if isinstance(val, str):
        s = val.strip()
        if not s:
            return []
        parts = re.split(r"\s*(?:,|ØŒ|/|\||&| Ùˆ | and )\s*", s, flags=re.I)
        return [p for p in parts if p]
    return []

def clean_channel_display(name: str) -> str:
    if not name:
        return ""
    s = str(name)
    s = EMOJI_MISC_RE.sub("", s)
    s = re.sub(r"\s*\((?:\$?\/?geo\/?R|geo\/?R|\$\/?geo|tjk)\)\s*", "", s, flags=re.I)
    s = re.sub(r"ğŸ“º|\[online\]|\[app\]", "", s, flags=re.I)
    s = re.sub(r"\s*hd\s*$", " HD", s, flags=re.I)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def is_bein_channel(name: str) -> bool:
    return bool(BEIN_RE.search(name or ""))

# ==== Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø© (whitelist) ÙƒÙ…Ø§ Ù‡ÙŠ ====
SUPPORTED_CHANNELS = [
    "MATCH! Futbol 1", "MATCH! Futbol 2", "MATCH! Futbol 3",
    "Football HD",
    "Sport TV1 Portugal HD", "Sport TV2 Portugal HD",
    "ESPN 1 Brazil", "ESPN 2 Brazil", "ESPN 3 Brazil", "ESPN 4 Brazil", "ESPN 5 Brazil", "ESPN 6 Brazil", "ESPN 7 Brazil",
    "DAZN 1 Portugal HD", "DAZN 2 Portugal HD", "DAZN 3 Portugal HD", "DAZN 4 Portugal HD", "DAZN 5 Portugal HD", "DAZN 6 Portugal HD",
    "MATCH! Premier HD", "Sky Sports Main Event HD", "Sky Sport Premier League HD", "IRIB Varzesh HD",
    "Persiana Sport HD", "MBC Action HD", "TNT Sports 1 HD", "TNT Sports 2 HD", "TNT Sports HD",
    "MBC masrHD", "MBC masr2HD", "ssc1 hd", "ssc2 hd", "Shahid MBC",
    # ØªØ·Ø¨ÙŠÙ‚Ùƒ (Ø¬Ø¯ÙŠØ¯)
    "Thmanyah 1", "Thmanyah 2", "Thmanyah 3",
    "Starzplay 1", "Starzplay 2",
    "Abu Dhabi Sport 1", "Abu Dhabi Sport 2",
]
ALLOWED_SUBSTRINGS = {
    "ssc ", " ssc", "ssc1", "ssc2", "ssc3", "ssc4", "ssc5", "ssc6", "ssc7", "ssc extra", "ssc sport",
    "alkass", "al kass", "al-kass", "Ø§Ù„ÙƒØ§Ø³", "Ø§Ù„ÙƒØ£Ø³",
    "shahid", "shahid vip", "shahid mbc",
    "mbc action", "persiana sport", "irib varzesh", "football hd",
    "thmanyah", "starzplay", "abu dhabi sport"
}

_supported_tokens = set()
for c in SUPPORTED_CHANNELS:
    cl = c.lower()
    _supported_tokens.add(cl)
    _supported_tokens.add(cl.replace(" hd", ""))

def is_supported_channel(name: str) -> bool:
    if not name:
        return False
    n = name.lower()
    if any(tok in n for tok in _supported_tokens):
        return True
    if any(sub in n for sub in ALLOWED_SUBSTRINGS):
        return True
    return False

# ==== ØªÙˆØ­ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ù„Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø± ====
CHANNEL_CANON_RULES = [
    (re.compile(r"thmanyah\s*(\d+)", re.I),                lambda m: (f"thmanyah-{m.group(1)}", f"Thmanyah {m.group(1)}")),
    (re.compile(r"starzplay\s*(\d+)", re.I),               lambda m: (f"starzplay-{m.group(1)}", f"Starzplay {m.group(1)}")),
    (re.compile(r"starzplay\b", re.I),                     lambda m: ("starzplay-1", "Starzplay 1")),
    (re.compile(r"abu\s*dhabi\s*sport\s*(\d+)", re.I),     lambda m: (f"abudhabi-{m.group(1)}", f"Abu Dhabi Sport {m.group(1)}")),
    (re.compile(r"(al[\s-]?kass|Ø§Ù„ÙƒØ§Ø³|Ø§Ù„ÙƒØ£Ø³)\s*(?:channel\s*)?(\d+)", re.I),
                                                       lambda m: (f"alkass-{m.group(2)}", f"Alkass {m.group(2)} HD")),
    (re.compile(r"^(?:Ø§Ù„ÙƒØ§Ø³|Ø§Ù„ÙƒØ£Ø³)\s*(\d+)", re.I),     lambda m: (f"alkass-{m.group(1)}", f"Alkass {m.group(1)} HD")),
    (re.compile(r"^al\s*kass\s*(\d+)", re.I),           lambda m: (f"alkass-{m.group(1)}", f"Alkass {m.group(1)} HD")),
    (re.compile(r"^alkass\s*(\d+)", re.I),              lambda m: (f"alkass-{m.group(1)}", f"Alkass {m.group(1)} HD")),
    (re.compile(r"ssc\s*extra", re.I),                   lambda m: ("ssc-extra", "SSC Extra HD")),
    (re.compile(r"ssc\s*(\d+)", re.I),                   lambda m: (f"ssc-{m.group(1)}", f"SSC {m.group(1)} HD")),
    (re.compile(r"shahid\s*(vip)?", re.I),               lambda m: ("shahid", "Shahid MBC")),
    (re.compile(r"football\s*hd", re.I),                 lambda m: ("football-hd", "Football HD")),
    (re.compile(r"sky\s*sport[s]?\s*premier\s*league", re.I),
                                                       lambda m: ("sky-premier-league", "Sky Sport Premier League HD")),
    (re.compile(r"sky\s*sport[s]?\s*main\s*event", re.I),
                                                       lambda m: ("sky-main-event", "Sky Sports Main Event HD")),
    (re.compile(r"dazn\s*1\s*portugal", re.I),           lambda m: ("dazn-pt-1", "DAZN 1 Portugal HD")),
    (re.compile(r"dazn\s*2\s*portugal", re.I),           lambda m: ("dazn-pt-2", "DAZN 2 Portugal HD")),
    (re.compile(r"dazn\s*3\s*portugal", re.I),           lambda m: ("dazn-pt-3", "DAZN 3 Portugal HD")),
    (re.compile(r"mbc\s*action", re.I),                  lambda m: ("mbc-action", "MBC Action HD")),
    (re.compile(r"persiana\s*sport", re.I),              lambda m: ("persiana-sport", "Persiana Sport HD")),
    (re.compile(r"irib\s*varzesh", re.I),                lambda m: ("irib-varzesh", "IRIB Varzesh HD")),
    (re.compile(r"tnt\s*sports?\s*1", re.I),             lambda m: ("tnt-1", "TNT Sports 1 HD")),
    (re.compile(r"tnt\s*sports?\s*2", re.I),             lambda m: ("tnt-2", "TNT Sports 2 HD")),
]

def channel_key_and_display(raw_name: str) -> tuple[str, str]:
    disp = clean_channel_display(raw_name)
    low = disp.lower()

    if is_bein_channel(disp):
        # Ù†Ø³Ù…Ø­ Ø¨Ø¹Ø±Ø¶ beIN Ù„ÙƒÙ† Ù„Ù† Ù†Ø£Ø®Ø° beIN Ù…Ù† live ÙÙŠÙ…Ø§ Ø¨Ø¹Ø¯
        has_mena = bool(re.search(r'\bmena\b|\bmiddle\s*east\b', low))
        mnum = re.search(r'\b(\d+)\b', disp)
        if has_mena and mnum:
            return (f"bein-mena-{mnum.group(1)}", f"beIN Sports MENA {mnum.group(1)} HD")
        if has_mena:
            return ("bein-mena", "beIN Sports MENA HD")
        if mnum:
            return (f"bein-{mnum.group(1)}", f"beIN Sports {mnum.group(1)} HD")
        return ("bein", "beIN Sports HD")

    for pat, conv in CHANNEL_CANON_RULES:
        m = pat.search(disp)
        if m:
            key, fixed = conv(m)
            return (key.lower(), fixed)

    return (low, disp)

def dedupe_channels_preserve_order(ch_list: list[str]) -> list[str]:
    seen_keys = set()
    out_disp = []
    for ch in ch_list:
        if not ch:
            continue
        key, disp = channel_key_and_display(ch)
        if key in seen_keys:
            continue
        seen_keys.add(key)
        out_disp.append(disp)
    return out_disp

# ==== Ù‚Ø§Ù…ÙˆØ³ AR -> EN ØµØºÙŠØ± Ù„Ø²ÙŠØ§Ø¯Ø© ÙØ±Øµ Ø§Ù„ØªØ·Ø§Ø¨Ù‚ ====
AR2EN = {
    "Ø±ÙŠØ§Ù„ Ù…Ø¯Ø±ÙŠØ¯": "Real Madrid",
    "Ù…Ø§Ø±Ø³ÙŠÙ„ÙŠØ§": "Marseille",
    "Ø¨Ø±Ø´Ù„ÙˆÙ†Ø©": "Barcelona",
    "Ø§ØªÙ„ØªÙŠÙƒÙˆ Ù…Ø¯Ø±ÙŠØ¯": "Atletico Madrid",
    "Ø¨Ø§ÙŠØ±Ù† Ù…ÙŠÙˆÙ†Ø®": "Bayern Munich",
    "Ø§Ù†ØªØ±": "Inter",
    "Ù…ÙŠÙ„Ø§Ù†": "AC Milan",
    "ÙŠÙˆÙÙ†ØªÙˆØ³": "Juventus",
    "Ø±ÙˆÙ…Ø§": "Roma",
    "Ù„ÙŠÙØ±Ø¨ÙˆÙ„": "Liverpool",
    "Ù…Ø§Ù†Ø´Ø³ØªØ± Ø³ÙŠØªÙŠ": "Manchester City",
    "Ù…Ø§Ù†Ø´Ø³ØªØ± ÙŠÙˆÙ†Ø§ÙŠØªØ¯": "Manchester United",
    "Ø§Ø±Ø³Ù†Ø§Ù„": "Arsenal",
    "ØªÙˆØªÙ†Ù‡Ø§Ù…": "Tottenham",
    "Ø¨Ø§Ø±ÙŠØ³ Ø³Ø§Ù† Ø¬ÙŠØ±Ù…Ø§Ù†": "Paris Saint-Germain",
    "Ù…Ø§Ø±Ø³ÙŠÙ„ÙŠØ§": "Marseille",
}

def ar_to_en_guess(name_ar: str) -> str:
    name_ar = (name_ar or "").strip()
    if not name_ar:
        return ""
    # Ù‚Ø§Ù…ÙˆØ³ Ù…Ø¨Ø§Ø´Ø±
    if name_ar in AR2EN:
        return AR2EN[name_ar]
    return name_ar  # fallback (Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø£ØµÙ„Ø§Ù‹ Ø¥Ù†ÙƒÙ„ÙŠØ²ÙŠ ÙÙŠ Ø¨Ø¹Ø¶ Ù…ØµØ§Ø¯Ø± ÙŠÙ„Ø§)

# ==== parsing Ù„Ù…Ø¨Ø§Ø±Ø§Ø© Ù…Ù† title ====
def parse_title_to_teams_generic(title: str) -> tuple[str | None, str | None]:
    if not title:
        return None, None
    t = title.strip()
    DELIMS = [
        r"\s+v(?:s)?\.?\s+",
        r"\s+-\s+", r"\s+â€“\s+", r"\s+â€”\s+",
        r"\s*:\s*", r"\s*\|\s*", r"\s*Â·\s*", r"\s*;\s*",
    ]
    for d in DELIMS:
        parts = re.split(d, t, maxsplit=1)
        if len(parts) == 2:
            l, r = parts[0].strip(), parts[1].strip()
            if l and r:
                return l, r
    return None, None

# ==== Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙØ±Ù‚ liveonsat ====
def extract_live_match(m: dict) -> tuple[str | None, str | None]:
    home = (m.get("home") or m.get("home_team"))
    away = (m.get("away") or m.get("away_team"))
    if home and away:
        return str(home).strip(), str(away).strip()
    title = (m.get("title") or "").strip()
    return parse_title_to_teams_generic(title)

# ==== Ø¨Ù†Ø§Ø¡ ÙÙ‡Ø±Ø³ liveonsat Ø¨Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø© ÙÙ‚Ø· (Ø¨Ø¯ÙˆÙ† beIN) ====
def build_live_index(live_data: dict):
    idx = []
    matches = (live_data or {}).get("matches", []) or []
    for m in matches:
        h_en, a_en = extract_live_match(m)
        if not h_en or not a_en:
            continue

        # Ù‚Ù†ÙˆØ§Øª Ù…Ø³Ù…ÙˆØ­Ø© ÙÙ‚Ø·ØŒ Ù…Ø¹ ØªØ¬Ø§Ù‡Ù„ beIN
        raw_channels = []
        for ck in ("channels_raw", "channels", "tv_channels", "broadcasters", "broadcaster"):
            if ck in m and m[ck]:
                raw = m[ck]
                if isinstance(raw, list):
                    raw_channels.extend([str(x) for x in raw])
                elif isinstance(raw, str):
                    raw_channels.extend(to_list_channels(raw))

        filtered = []
        for ch in raw_channels:
            disp = clean_channel_display(ch)
            if not disp:
                continue
            if is_bein_channel(disp):
                continue  # Ù„Ø§ Ù†Ø£Ø®Ø° beIN Ù…Ù† live
            if is_supported_channel(disp):
                filtered.append(disp)

        filtered = dedupe_channels_preserve_order(filtered)

        # Ø®Ø²Ù‘Ù† Ø¹Ù†ØµØ± ÙÙ‡Ø±Ø³ (Ù†Ø³ØªØ¹Ù…Ù„ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø¯Ù„ dict Ù„Ù†Ø³ØªØ·ÙŠØ¹ Ø¹Ù…Ù„ Ù…Ø·Ø§Ø¨Ù‚Ø© ØªÙ‚Ø±ÙŠØ¨ÙŠØ©)
        idx.append({
            "home_en": h_en,
            "away_en": a_en,
            "home_en_norm": normalize_text(h_en),
            "away_en_norm": normalize_text(a_en),
            "title": (m.get("title") or "").strip(),
            "title_norm": normalize_text(m.get("title") or ""),
            "competition": (m.get("competition") or "").strip(),
            "kickoff_baghdad": (m.get("kickoff_baghdad") or m.get("time_baghdad") or m.get("kickoff") or "").strip(),
            "channels_allowed": filtered,   # ÙÙ‚Ø· Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø©
        })
    return idx

def minutes_from_hhmm(hhmm: str) -> int | None:
    m = TIME_RE.match((hhmm or "").strip())
    if not m:
        return None
    h, mi = int(m.group(1)), int(m.group(2))
    return h * 60 + mi

def times_close(t1: str, t2: str, tol_min: int = 30) -> bool:
    m1 = minutes_from_hhmm(t1)
    m2 = minutes_from_hhmm(t2)
    if m1 is None or m2 is None:
        return True  # Ø¥Ø°Ø§ Ù…Ø§ÙƒÙˆ ÙˆÙ‚ØªÙŠÙ† Ù…Ø¹ØªØ¨Ø±ÙŠÙ†ØŒ Ù„Ø§ Ù†Ù…Ù†Ø¹ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
    return abs(m1 - m2) <= tol_min

# ==== Ù…Ø·Ø§Ø¨Ù‚Ø© ØªÙ‚Ø±ÙŠØ¨ÙŠØ© Ø¨ÙŠÙ† yalla (AR/EN) Ùˆ live (EN) ====
def likely_same_match(y_item: dict, live_item: dict) -> bool:
    # Ù…ØµØ§Ø¯Ø± Ø£Ø³Ù…Ø§Ø¡ Ù…Ù† ÙŠÙ„Ø§: home/away Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØŒ ÙˆÙ…Ø­Ø§ÙˆÙ„Ø© ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ù„Ø¥Ù†ÙƒÙ„ÙŠØ²ÙŠØŒ ÙˆÙƒØ°Ù„Ùƒ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†
    h_ar = (y_item.get("home") or y_item.get("home_team") or "").strip()
    a_ar = (y_item.get("away") or y_item.get("away_team") or "").strip()
    h_en_guess = (y_item.get("home_en") or ar_to_en_guess(h_ar)).strip()
    a_en_guess = (y_item.get("away_en") or ar_to_en_guess(a_ar)).strip()

    # Ø¹Ù†Ø§ÙˆÙŠÙ†
    titles_try = [
        (y_item.get("title_en") or "").strip(),
        (y_item.get("title") or "").strip(),
        (y_item.get("title_ar") or "").strip(),
    ]
    title_pairs = []
    for t in titles_try:
        l, r = parse_title_to_teams_generic(t)
        if l and r:
            title_pairs.append((l.strip(), r.strip()))

    # Ù†Ø¨Ù†ÙŠ Ù…Ø±Ø´Ù‘Ø­Ø§Øª Ù†ØµÙŠØ© Ù…Ø·Ø¨Ù‘Ø¹Ø© (partial substring) Ù„ÙƒÙ„Ø§ Ø§Ù„ÙØ±ÙŠÙ‚ÙŠÙ†
    cand_pairs = []
    if h_en_guess and a_en_guess:
        cand_pairs.append((h_en_guess, a_en_guess))
    cand_pairs.extend(title_pairs)

    if not cand_pairs:
        # Ù…Ø§ÙƒÙˆ Ø£Ø³Ù…Ø§Ø¡ EN ÙƒØ§ÙÙŠØ©: Ù…Ø§ Ù†Ù‚Ø¯Ø± Ù†Ø¶Ù…Ù† Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
        return False

    lh, la = live_item["home_en_norm"], live_item["away_en_norm"]
    for (ph, pa) in cand_pairs:
        nh, na = normalize_text(ph), normalize_text(pa)
        # ØªØ­Ù…Ù‘Ù„ Ø§Ù„ØªØ±ØªÙŠØ¨ÙŠÙ†ØŒ ÙˆØ¨Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¬Ø²Ø¦ÙŠØ© Ø¨Ø§Ù„Ø§ØªØ¬Ø§Ù‡ÙŠÙ†
        cond1 = (nh in lh or lh in nh) and (na in la or la in na)
        cond2 = (nh in la or la in nh) and (na in lh or lh in na)
        if cond1 or cond2:
            # ØªØ­Ù‚Ù‚ ÙˆÙ‚Øª Ù‚Ø±ÙŠØ¨ (Ø¥Ù† Ø£Ù…ÙƒÙ†)
            if times_close(y_item.get("kickoff_baghdad") or y_item.get("time_baghdad") or y_item.get("kickoff") or "",
                           live_item.get("kickoff_baghdad") or ""):
                return True
    return False

# ==== Ù‚Ù†ÙˆØ§Øª ÙŠÙ„Ø§ Ø´ÙˆØª ====
def collect_yalla_channels(y: dict) -> list:
    keys_try = ["channels_raw", "channels", "tv_channels", "channel", "channel_ar", "channel_en", "broadcasters", "broadcaster"]
    out = []
    for k in keys_try:
        if k in y:
            out.extend(to_list_channels(y.get(k)))
    return unique_preserving(out)

def pick_primary_yalla_channel(chs: list[str]) -> str | None:
    """Starzplay Ø£ÙˆÙ„Ø§Ù‹ØŒ Ø¨Ø¹Ø¯Ù‡Ø§ beINØŒ Ø¨Ø¹Ø¯Ù‡Ø§ Ø£ÙˆÙ„ Ù‚Ù†Ø§Ø©."""
    if not chs:
        return None
    cleaned = [clean_channel_display(c) for c in chs if c]
    for c in cleaned:
        if "starzplay" in c.lower():
            return c
    for c in cleaned:
        if is_bein_channel(c):
            return c
    return cleaned[0] if cleaned else None

# ==== Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ====
def filter_matches():
    # 1) Ø§Ù‚Ø±Ø£ ÙŠÙ„Ø§ Ø´ÙˆØª (Ù…ØµØ¯Ø± Ø£Ø³Ø§Ø³ÙŠ)
    try:
        yresp = requests.get(YALLASHOOT_URL, timeout=25)
        yresp.raise_for_status()
        yalla = yresp.json()
    except Exception as e:
        print(f"[x] ERROR fetching yallashoot: {e}")
        return

    y_matches = (yalla or {}).get("matches", []) or []

    # 2) Ø§Ù‚Ø±Ø£ liveonsat Ù„Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ© (Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø© ÙÙ‚Ø·)
    try:
        with INPUT_PATH_LIVE.open("r", encoding="utf-8") as f:
            live_data = json.load(f)
    except Exception as e:
        print(f"[!] WARN: cannot read liveonsat file: {e}")
        live_data = {"matches": []}

    live_idx = build_live_index(live_data)

    # 3) Ø¯Ù…Ø¬: Ù„ÙƒÙ„ Ù…Ø¨Ø§Ø±Ø§Ø© Ù…Ù† ÙŠÙ„Ø§ Ø´ÙˆØªØŒ Ù†Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¨Ø§Ù„Ù€ live Ù„Ù†ÙØ³ Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø©
    out_matches = []
    matched_extra = 0
    for m in y_matches:
        # Ù‚Ù†Ø§Ø© ÙŠÙ„Ø§ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        y_chs = collect_yalla_channels(m)
        primary = pick_primary_yalla_channel(y_chs)
        merged = []
        if primary:
            merged.append(clean_channel_display(primary))

        # Ø§Ø¨Ø­Ø« Ø¹Ù† live match Ù…Ø·Ø§Ø¨Ù‚
        best_live = None
        for li in live_idx:
            if likely_same_match(m, li):
                best_live = li
                break

        # Ù„Ùˆ Ù„Ù‚ÙŠÙ†Ø§ live Ù…Ø·Ø§Ø¨Ù‚ØŒ Ø£Ø¶Ù Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø© ÙÙ‚Ø· (Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¯Ø§Ø®Ù„ li["channels_allowed"])
        if best_live and best_live["channels_allowed"]:
            merged.extend(best_live["channels_allowed"])
            matched_extra += 1

        # dedupe + ØªØ±ØªÙŠØ¨ Ù†Ù‡Ø§Ø¦ÙŠ
        merged = dedupe_channels_preserve_order(merged)

        out = {
            "competition": m.get("competition") or "",
            "kickoff_baghdad": m.get("kickoff_baghdad") or m.get("time_baghdad") or m.get("kickoff") or "",
            "home_team": (m.get("home") or m.get("home_team") or "").strip(),
            "away_team": (m.get("away") or m.get("away_team") or "").strip(),
            "channels_raw": merged,
            "home_logo": m.get("home_logo"),
            "away_logo": m.get("away_logo"),
            "status_text": m.get("status_text"),
            "result_text": m.get("result_text"),
        }
        out_matches.append(out)

    # 4) ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù†Ø§ØªØ¬
    output = {
        "date": yalla.get("date"),
        "source_url": "yallashoot (primary) + liveonsat (extra whitelisted channels)",
        "matches": out_matches
    }
    with OUTPUT_PATH.open("w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"[âœ“] Done. yalla: {len(y_matches)} | matched extra channels from live: {matched_extra} | written: {len(out_matches)}")

if __name__ == "__main__":
    filter_matches()
